Кластеризация, или кластерный анализ, представляет собой метод группировки объектов в подмножества, называемые кластерами, таким образом, чтобы объекты внутри одного кластера были максимально похожи друг на друга, а объекты из разных кластеров — максимально различны. Этот подход используется в ситуациях, когда заранее неизвестно, как организованы данные, и позволяет выявить скрытые структуры в больших объемах информации.

## Формальное определение кластеризации

Кластеризация - это задача разбиения множества объектов на подмножества, называемые кластерами, таким образом, чтобы:

1. Каждый объект принадлежал ровно одному кластеру.
2. Объекты внутри одного кластера были максимально похожи друг на друга по некоторой метрике сходства или расстояния.
3. Объекты из разных кластеров были максимально различны по той же метрике.

Формально, пусть дано множество объектов $$ X = \{x_1, x_2, \ldots, x_n\} $$Требуется найти разбиение X на непересекающиеся подмножества C1, C2, ..., Ck, называемые кластерами, такое что:

1. $$ \bigcup_{i=1}^k C_i = X $$Объединение всех множеств Ci​ для i от 1 до k равно множеству X. Это формальное выражение указывает на то, что каждый элемент, который принадлежит хотя бы одному из множеств Ci, также принадлежит множеству X.

2. $$ C_i \cap C_j = \emptyset \quad \forall i \neq j $$Данное равенство гарантирует, что в результате кластеризации все объекты из исходного множества X будут распределены по кластерам C1, C2, ..., Ck. Каждый объект должен быть отнесен ровно к одному кластеру, что обеспечивается условием непересекаемости кластеров.

3. $$ \sum_{x \in C_i} d(x, c_i) \leq \sum_{x \in C_i} d(x, c_j) \quad \forall i \neq j $$
$$ \sum_{x \in C_i} d(x, c_i) $$ 
Это сумма расстояний от всех объектов x, принадлежащих кластеру Ci​, до центра этого кластера ci. Оно представляет собой метрику расстояния между объектом x и центром кластера ci​. Обычно используется евклидово расстояние, но могут применяться и другие метрики в зависимости от задачи.

$$ \sum_{x \in C_i} d(x, c_j) $$ 
Это сумма расстояний от всех объектов x в кластер Ci​ до центра другого кластера cj, где j не равно i.

Эта запись означает следующее:

- **Минимизация расстояний**: Для каждого кластера Ci​ сумма расстояний от его объектов до центра ci​ должна быть меньше или равна сумме расстояний от тех же объектов до центра любого другого кластера cj​(cj - центр масс класстера Cj), где j не равно i. Это условие гарантирует, что объекты в кластере Ci​ действительно более близки к своему центру, чем к центрам других кластеров.

- **Обоснование разбиения**: Это условие является основой для того, чтобы утверждать, что кластеризация выполнена корректно. Если бы сумма расстояний до центра другого кластера была меньше, это означало бы, что объекты в Ci​ на самом деле ближе к cj​, и, следовательно, их следовало бы перенести в кластер Cj​.


`БОЛЕЕ ДОСТУПНЫМ ЯЗЫКОМ:` **Для того, чтобы разбить множество на кластеры, вводится понятие расстояния или удаленности объектов от центра каждого кластера. Условно можно представить, что у каждого кластера есть свой центр масс. Критерием правильного разбиения на непересекающиеся кластеры является следующее:**

- **Если суммарное расстояние объектов кластера Ci до центра этого кластера ci меньше, чем суммарное расстояние тех же объектов до центра любого другого кластера cj, то эти объекты с большей вероятностью принадлежат кластеру Ci, а не Cj.**

Другими словами, объекты в кластере должны быть ближе к центру своего кластера, чем до центров других кластеров. Это позволяет разбить множество на непересекающиеся группы похожих объектов. 


## Немного иная формализация задачи

Пусть X — множество объектов, Y — множество идентификаторов (меток) кластеров. На множестве X задана функция расстояния между объектами $$ ρ(x,x′) $$ Дана конечная обучающая выборка объектов $$ X_m = \{x_1, \ldots, x_m\} \subset X $$Необходимо разбить выборку на подмножества (кластеры), то есть каждому объекту $$xi \in Xm$$ сопоставить метку $$yi \in Y$$, таким образом чтобы объекты внутри каждого кластера были близки относительно метрики ρ, а объекты из разных кластеров значительно различались.

**Алгоритм кластеризации** — функция a:X→Y, которая любому объекту x∈X ставит в соответствие идентификатор кластера y∈Y.

**Кластеризация (обучение без учителя) отличается от классификации (обучения с учителем) тем, что метки объектов из обучающей выборки yi изначально не заданы, и даже может быть неизвестно само множество Y.**

Решение задачи кластеризации объективно неоднозначно по ряду причин:

- Не существует однозначного критерия качества кластеризации. Известен ряд алгоритмов, осуществляющих разумную кластеризацию "по построению", однако все они могут давать разные результаты. Следовательно, для определения качества кластеризации и оценки выделенных кластеров необходим эксперт предметной области;

- Число кластеров, как правило, заранее не известно и выбирается по субъективным критериям. Даже если алгоритм не требует изначального знания о числе классов, конкретные реализации зачастую требуют указать этот параметр;

- Результат кластеризации существенно зависит от метрики. Однако существует ряд рекомендаций по выбору метрик для определенных классов задач.

## Основная задача класстеризации

Основная задача кластеризации, в том числе и с использованием алгоритма [[K-срдених]], заключается в определении центров масс (центроидов) кластеров, а также в распределении объектов данных по этим кластерам таким образом, чтобы минимизировать некоторую меру расстояния(обычно это квадрат расстояния) между объектами и их центроидами.

Центроиды представляют собой условные точки, вокруг которых группируются объекты данных. В алгоритме k-средних центроид каждого кластера пересчитывается как среднее значение всех объектов, принадлежащих этому кластеру. Таким образом, центроиды можно рассматривать как "плотности и масс сосредоточений" объектов в пространстве признаков.

Идеальное решение задачи кластеризации должно удовлетворять двум основным критериям:
1. Внутри каждого кластера объекты должны быть максимально схожи друг с другом (иметь минимальное расстояние между собой).

2. Объекты из разных кластеров должны быть максимально различны (иметь максимальное расстояние между кластерами).

Алгоритм k-средних и другие методы кластеризации стремятся найти такое разбиение данных на кластеры, которое минимизирует общую сумму квадратов расстояний от каждого объекта до центра его кластера. Это эквивалентно поиску центроидов, которые наилучшим образом представляют свои кластеры в смысле выбранной метрики расстояния.

## Цели кластеризации

Кластеризация применяется в различных областях, включая маркетинг, биоинформатику и социологию. Основные цели включают:

- **Понимание данных**: Помогает аналитикам определить, по каким признакам можно сгруппировать данные.

- **Выявление аномалий**: Позволяет находить объекты, которые не вписываются в существующие кластеры, что может указывать на интересные феномены или ошибки в данных.

### Методы кластеризации

- Графовые алгоритмы кластеризации. Наиболее примитивный класс алгоритмов. В настоящее время практически не применяется на практике;

- Вероятностные алгоритмы кластеризации. Каждый объект из обучающей выборки относится к каждому из кластеров с определенной степенью вероятности: [EM-алгоритм](https://neerc.ifmo.ru/wiki/index.php?title=EM-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC "EM-алгоритм");

- [Иерархические алгоритмы кластеризации](https://neerc.ifmo.ru/wiki/index.php?title=%D0%98%D0%B5%D1%80%D0%B0%D1%80%D1%85%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F "Иерархическая кластеризация"). Упорядочивание данных путем создания иерархии вложенных кластеров;

- -Алгоритм [[K-срдених]] (англ. k-means). Итеративный алгоритм, основанный на минимизации суммарного квадратичного отклонения точек кластеров от центров этих кластеров;

- Распространение похожести (англ. _affinity propagation_). Распространяет сообщения о похожести между парами объектов для выбора типичных представителей каждого кластера;

- Сдвиг среднего значения (англ. _mean shift_). Выбирает центроиды кластеров в областях с наибольшей плотностью;

- Спектральная кластеризация (англ. _spectral clustering_). Использует собственные значения матрицы расстояний для понижения размерности перед использованием других методов кластеризации;

- Основанная на плотности пространственная кластеризация для приложений с шумами (англ. _Density-based spatial clustering of applications with noise_, _DBSCAN_). Алгоритм группирует в один кластер точки в области с высокой плотностью. Одиноко расположенные точки помечает как шум.
