Связанные темы: [[Дисперсия]]

Коэффициент детерминации, обозначаемый как ( R^2 ), является одним из наиболее важных показателей, используемых в статистике для оценки качества модели регрессии. Он представляет собой долю дисперсии зависимой переменной, объясняемой моделью независимыми переменными. Более точно — это единица минус доля необъяснённой дисперсии (дисперсии случайной ошибки модели, или условной по факторам дисперсии зависимой переменной) в дисперсии зависимой переменной.
#### $$ 
	R^2 = 1 - \frac{SS_\text{res}} {SS_\text{tot}}
$$
#### $$
\begin{align*}
SS_\text{res} = \sum{(y_\text{i} - y_\text{i}`)^2} - 
\text{сумма квадратов остатков регрессии (сумма кдвадратов разностей между фактическими и прогнозруемыми значениями)}
\end{align*}
$$
#### $$ 
SS_\text{tot} = \sum{(y_\text{i} - \hat{y_\text{i}})^2} - \text{Общая сумма квадратов(сумма квадратов разностей между фактическими и средними значенями)}
$$
#### $$
y_\text{i}, y_\text{i}`, \hat{y} - \text{фактические расчтеные и срееднее значения обьясняемой перменной}
$$

Значение ( R^2 ) лежит в диапазоне от 0 до 1, где:
- 1 означает, что модель полностью объясняет дисперсию зависимой переменной.
- 0 означает, что модель не объясняет дисперсию вообще.
- Отрицательные значения означают, что модель работает хуже, чем просто предсказывает среднее значение зависимой переменной.

Однако, важно понимать, что добавление новых переменных в модель всегда может увеличивать ( R^2 ), даже если эти переменные не несут дополнительной информации. Это называется переобучением модели и является одним из основных проблем в статистике.